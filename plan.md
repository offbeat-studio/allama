# AI API 服務器開發計劃

## 項目目標
建立一個使用 Golang 和 Gin 框架的服務器，提供各種 AI 提供商的 API 接口，並能根據模型轉接到任何其他 AI 提供商。服務器使用 SQLite 進行簡單的資料存儲，並通過 Docker 進行部署。至少支援 OpenAI、Anthropic 和 Ollama 三種接口和模型提供商。

## 任務列表

### 1. 建立 Golang 項目結構 ✅
   - 初始化 Golang 項目，創建必要的目錄結構（如 `cmd`、`internal`、`pkg`）。 ✅
   - 設定 `go.mod` 文件，定義項目名稱和依賴版本。 ✅

### 2. 安裝必要的依賴 ✅
   - 安裝 Gin 框架作為 HTTP 服務器框架。 ✅
   - 安裝 SQLite 驅動程式以支援資料庫存儲。 ✅
   - 安裝其他必要的庫（如用於 HTTP 請求、JSON 處理等）。 ✅

### 3. 設計 API 接口 ✅
   - 定義統一的 API 端點結構，支援多個 AI 提供商的模型調用（如 `/api/v1/models`，`/api/v1/chat`）。 ✅
   - 設計請求和響應格式，確保與 OpenAI、Anthropic 和 Ollama 的 API 兼容。 ✅
   - 制定模型選擇和轉接的邏輯，允許用戶指定模型或自動選擇最佳提供商。 ✅

### 4. 設定 SQLite 資料庫 ✅
   - 建立資料庫 schema，存儲 API 金鑰、模型配置、用戶偏好等信息。 ✅
   - 實現資料庫初始化和遷移機制，確保服務啟動時資料庫結構正確。 ✅
   - 提供基本的 CRUD 操作，用於管理資料庫中的配置數據。 ✅
   - 整合初始化邏輯到服務啟動過程中，確保服務啟動時自動插入默認數據。 ✅

### 5. 整合 AI 提供商接口 ✅
   - **OpenAI**：實現 OpenAI API 的調用邏輯，支援其模型列表和聊天功能。 ✅
   - **Anthropic**：實現 Anthropic API 的調用邏輯，支援 Claude 模型的調用。 ✅
   - **Ollama**：實現 Ollama API 的調用邏輯，支援本地或遠程 Ollama 模型。 ✅
   - 為每個提供商建立單獨的模塊，方便未來擴展其他 AI 提供商。 ✅

### 6. 建立路由和轉接邏輯 ✅
   - 在 Gin 框架中設定路由，處理 API 請求。 ✅
   - 根據請求中的模型識別碼或配置，動態轉接到相應的 AI 提供商。 ✅
   - 實現錯誤處理和日誌記錄，確保請求過程可追蹤。 ✅

### 7. 撰寫 Docker 檔案和部署設定 ✅
   - 建立 `Dockerfile`，定義 Golang 環境、依賴安裝和服務器構建步驟。 ✅
   - 建立 `docker-compose.yml`，設定服務器和資料庫的容器配置，支援一鍵部署。 ✅
   - 提供環境變數設定，用於配置 API 金鑰和其他敏感信息。 ✅

### 8. 測試服務器功能
   - 編寫單元測試，驗證 API 接口和轉接邏輯的正確性。
   - 進行整合測試，確保與 OpenAI、Anthropic 和 Ollama 的連接和響應正常。
   - 模擬不同模型和提供商的請求，測試服務器的穩定性和性能。

### 9. 提供部署指南和說明文件
   - 撰寫 README 文件，說明項目功能、安裝步驟和使用方法。
   - 提供 API 文檔，詳細描述每個端點的參數和響應格式。
   - 提供 Docker 部署指南，幫助用戶快速啟動服務器。

## 時間估計
- 項目結構和依賴安裝：1 天
- API 設計和資料庫設定：2 天
- AI 提供商整合：3 天（每個提供商約 1 天）
- 路由邏輯和測試：2 天
- Docker 部署和文件撰寫：2 天
- 總計：10 天

## 注意事項
- 確保 API 金鑰和敏感信息的存儲和傳輸安全。
- 考慮未來擴展性，設計模塊化結構以支援更多 AI 提供商。
- 在開發過程中，定期與用戶確認需求和進度，確保方向正確。
